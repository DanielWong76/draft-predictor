{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3eaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9170c507",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_connection():\n",
    "    \"\"\"\n",
    "    Creates a connection to the postgresql server\n",
    "    \"\"\"\n",
    "    \n",
    "    load_dotenv()\n",
    "\n",
    "    # Accessing variables from .env file\n",
    "    db_name = os.getenv('DB_NAME')\n",
    "    db_user = os.getenv('DB_USER')\n",
    "    db_pass = os.getenv('DB_PASS')\n",
    "    db_host = os.getenv('DB_HOST')\n",
    "    db_port = os.getenv('DB_PORT')\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_pass,\n",
    "            host=db_host,\n",
    "            port=db_port\n",
    "        )\n",
    "        print(\"Connected to the database.\")\n",
    "        return (conn, conn.cursor())\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to the database.\")\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eaae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stat_list(stat_list):\n",
    "    \"\"\"\n",
    "    Takes in a list of stats and converts it to a string to be used in\n",
    "    a SQL query. \n",
    "    \"\"\"\n",
    "    return ', '.join(stat_list)\n",
    "    \n",
    "\n",
    "def load_data(cursor, stats, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Loads data from the postgresql database, returning numpy matrix of player stats\n",
    "    and numpy array of corresponding ratings of the players.\n",
    "    \n",
    "    stats: list containing stats that the model should train on\n",
    "    \"\"\"\n",
    "    stats = process_stat_list(stats)\n",
    "    query = f'SELECT {stats} FROM \"PlayerStats\" JOIN \"Players\" ON \"PlayerID\" WHERE \"DraftYear\" >= {start_year} AND \"DraftYear\" <= {end_year} ORDER BY \"PlayerID\";'\n",
    "    cursor.execute(query)\n",
    "    records = cursor.fetchall()\n",
    "    return np.array(records)\n",
    "\n",
    "def load_ratings(cursor, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Returns ratings of players in the database\n",
    "    \"\"\"\n",
    "    query = f'SELECT \"Rating\" FROM \"Players\" WHERE \"DraftYear\" >= {start_year} AND \"DraftYear\" <= {end_year} ORDER BY \"PlayerID\";'\n",
    "    cursor.execute(query)\n",
    "    records = cursor.fetchall()\n",
    "    return np.array(records).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fff01c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 1, 1, 1, 2, 1, 4, 1, 3, 2, 0, 0, 1, 1, 2, 1, 2, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 5, 3, 3, 4,\n",
       "       1, 1, 1, 2, 4, 0, 0, 0, 2, 0, 0, 2, 1, 0, 2, 0, 0, 0, 3, 3, 0, 0,\n",
       "       1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 1, 1, 0, 3, 2, 5, 2, 3, 0,\n",
       "       0, 0, 2, 0, 2, 1, 3, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 0, 3, 0, 0, 0,\n",
       "       0, 4, 4, 4, 1, 3, 4, 0, 3, 4, 2, 0, 0, 0, 2, 2, 0, 0, 4, 3, 1, 0,\n",
       "       0, 0, 3, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 5, 2, 4,\n",
       "       2, 2, 2, 5, 0, 2, 1, 3, 3, 0, 0, 3, 0, 4, 3, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 3, 5, 3, 1, 4, 5, 3, 0, 2,\n",
       "       2, 1, 2, 0, 1, 1, 1, 0, 0, 2, 5, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 5, 3, 4, 0, 3, 1, 2, 1, 3, 4, 0, 0, 1, 2, 2, 2, 1, 1, 0, 0,\n",
       "       3, 3, 0, 1, 1, 2, 0, 0, 1, 1, 1, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 2, 2, 2, 1, 2, 2, 0, 0, 0, 3, 2, 0, 2, 0, 0, 0, 5, 4, 0, 0,\n",
       "       0, 1, 1, 2, 0, 2, 3, 2, 5, 2, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_ratings(cursor, 2013, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT \"PlayerID\", \"PlayerName\", \"Rating\" FROM \"Players\" ORDER BY \"PlayerID\";')\n",
    "records = cursor.fetchall()\n",
    "for record in records:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4683b",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    \"\"\"Tree class.\n",
    "    \n",
    "    (You don't need to add any methods or fields here but feel\n",
    "    free to if you like. Our tests will only reference the fields\n",
    "    defined in the constructor below, so be sure to set these\n",
    "    correctly.)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, left, right, parent, cutoff_id, cutoff_val, prediction):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.parent = parent\n",
    "        self.cutoff_id = cutoff_id\n",
    "        self.cutoff_val = cutoff_val\n",
    "        self.prediction = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity_weighted(class_counts, total_weight):\n",
    "    \"\"\"\n",
    "    Calculates the weighted Gini impurity given the weighted counts of each class.\n",
    "    \n",
    "    Args:\n",
    "        class_counts: Array-like, containing the sum of the weights for each class.\n",
    "        total_weight: The sum of the weights of all instances.\n",
    "    Returns:\n",
    "        float: The weighted Gini impurity.\n",
    "    \"\"\"\n",
    "    # Calculate the squared proportion for each class\n",
    "    class_probs = (class_counts / total_weight) ** 2\n",
    "\n",
    "    # Calculate the weighted Gini impurity\n",
    "    impurity = 1 - np.sum(class_probs)\n",
    "    return impurity\n",
    "\n",
    "def sqsplit(xTr,yTr, classes, weights=[]):\n",
    "    \"\"\"Finds the best feature, cut value, and loss value.\n",
    "    \n",
    "    Input:\n",
    "        xTr:     n x d matrix of data points\n",
    "        yTr:     n-dimensional vector of labels\n",
    "        classes: number of classes\n",
    "        weights: n-dimensional weight vector for data points\n",
    "    \n",
    "    Output:\n",
    "        feature:  index of the best cut's feature\n",
    "        cut:      cut-value of the best cut\n",
    "        bestloss: loss of the best cut\n",
    "    \"\"\"\n",
    "    N,D = xTr.shape\n",
    "    assert D > 0 # must have at least one dimension\n",
    "    assert N > 1 # must have at least two samples\n",
    "    if weights == []: # if no weights are passed on, assign uniform weights\n",
    "        weights = np.ones(N)\n",
    "    weights = weights/sum(weights) # Weights need to sum to one (we just normalize them)\n",
    "    bestgain = -np.inf\n",
    "    feature = None\n",
    "    cut = None\n",
    "    counts = np.bincount(yTr, weights=weights, minlength = classes)\n",
    "    parent_impurity= gini_impurity_weighted(counts, 1.0)\n",
    "    \n",
    "    for d in range(D):\n",
    "        ii = xTr[:,d].argsort() # sort data along the dth dimension\n",
    "        xs = xTr[ii,d] # sorted feature values\n",
    "        ws = weights[ii] # sorted weights\n",
    "        ys = yTr[ii] # sorted labels\n",
    "        # np.finfo(float).eps gives us the smallest possible positive number that can be represented by floats. \n",
    "        idif = np.where(np.abs(np.diff(xs, axis=0)) > np.finfo(float).eps * 100)[0]\n",
    "\n",
    "        for j in idif:\n",
    "            if j+1 != len(yTr):\n",
    "                left_ys = ys[:j+1]\n",
    "                right_ys = ys[j+1:]\n",
    "                left_ws = ws[:j+1]\n",
    "                right_ws = ws[j+1:]\n",
    "\n",
    "                # Calculate weighted class counts for left and right\n",
    "                left_counts = np.bincount(left_ys, weights=left_ws, minlength = classes)\n",
    "                right_counts = np.bincount(right_ys, weights=right_ws, minlength = classes)\n",
    "\n",
    "                left_weight = np.sum(left_ws)\n",
    "                right_weight = np.sum(right_ws)\n",
    "\n",
    "                left_impurity = gini_impurity_weighted(left_counts, left_weight)\n",
    "                right_impurity = gini_impurity_weighted(right_counts, right_weight)\n",
    "\n",
    "                weighted_impurity = left_weight * left_impurity + right_weight * right_impurity`\n",
    "\n",
    "                gain = parent_impurity - weighted_impurity\n",
    "\n",
    "                if gain > bestgain:\n",
    "                    cut = (xs[j] + xs[j + 1]) / 2.0\n",
    "                    feature = d\n",
    "                    bestgain = gain\n",
    "\n",
    "    if feature is None or cut is None:\n",
    "        return None, None, -np.inf\n",
    "\n",
    "    return feature, cut, bestgain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart(xTr,yTr, classes, depth=np.inf,weights=None):\n",
    "    \"\"\"Builds a CART tree.\n",
    "    \n",
    "    The maximum tree depth is defined by \"maxdepth\" (maxdepth=2 means one split).\n",
    "    Each example can be weighted with \"weights\".\n",
    "\n",
    "    Args:\n",
    "        xTr:      n x d matrix of data\n",
    "        yTr:      n-dimensional vector\n",
    "        maxdepth: maximum tree depth\n",
    "        weights:  n-dimensional weight vector for data points\n",
    "\n",
    "    Returns:\n",
    "        tree: root of decision tree\n",
    "    \"\"\"\n",
    "    n,d = xTr.shape\n",
    "    if weights is None:\n",
    "        w = np.ones(n) / float(n)\n",
    "    else:\n",
    "        w = weights\n",
    "    \n",
    "    def majority_class(labels, classes, weights):\n",
    "        class_counts = np.bincount(labels, weights=weights, minlength=classes)\n",
    "        return np.argmax(class_counts)\n",
    "    \n",
    "    # TODO:\n",
    "    def treeRecursion(xTr, yTr, depth, weights):\n",
    "        # Base case: create a leaf node\n",
    "        if depth == 0 or len(yTr) <= 1:\n",
    "            # weighted_average = np.mean(yTr) if np.sum(weights) == 0 else np.divide(np.sum(yTr * weights), np.sum(weights))\n",
    "            return TreeNode(None, None, None, None, None, majority_class(yTr, classes, weights))\n",
    "\n",
    "        # Find the best split\n",
    "        feature, cut, _ = sqsplit(xTr, yTr, classes, weights)\n",
    " \n",
    "        # Check if a valid split is found\n",
    "        if feature is None or not isinstance(feature, int):\n",
    "            # weighted_average = np.mean(yTr) if np.sum(weights) == 0 else np.divide(np.sum(yTr * weights), np.sum(weights))\n",
    "            return TreeNode(None, None, None, None, None, majority_class(yTr, classes, weights))\n",
    "\n",
    "        # Partition the data\n",
    "        left_mask = xTr[:, feature] <= cut\n",
    "        right_mask = xTr[:, feature] > cut\n",
    "\n",
    "        # Check for empty splits\n",
    "        if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "            # weighted_average = np.mean(yTr) if np.sum(weights) == 0 else np.divide(np.sum(yTr * weights), np.sum(weights))\n",
    "            return TreeNode(None, None, None, None, None, majority_class(yTr, classes, weights))\n",
    "\n",
    "        # Recursive calls for left and right children\n",
    "        left_child = treeRecursion(xTr[left_mask], yTr[left_mask], depth - 1, weights[left_mask])\n",
    "        right_child = treeRecursion(xTr[right_mask], yTr[right_mask], depth - 1, weights[right_mask])\n",
    "\n",
    "        # Create the current node\n",
    "        #weighted_average = np.mean(yTr) if np.sum(weights) == 0 else np.divide(np.sum(yTr * weights), np.sum(weights))\n",
    "        node = TreeNode(left_child, right_child, None, feature, cut, majority_class(yTr, classes, weights))\n",
    "\n",
    "        # Update parent for children nodes\n",
    "        if left_child is not None:\n",
    "            left_child.parent = node\n",
    "        if right_child is not None:\n",
    "            right_child.parent = node\n",
    "\n",
    "        return node\n",
    "\n",
    "    return treeRecursion(xTr, yTr, depth , w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec728692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def evaltreehelper(root,xTe, idx=[]):\n",
    "    \"\"\"Evaluates xTe using decision tree root.\n",
    "    \n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "    \n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    assert root is not None\n",
    "    n = xTe.shape[0]\n",
    "    pred = np.zeros(n)\n",
    "    \n",
    "    # TODO:\n",
    "    for i in range(n):\n",
    "        data_point = xTe[i]\n",
    "        node = root\n",
    "        while node is not None:\n",
    "            if node.cutoff_id is None:  # Check if it is a leaf node\n",
    "                pred[i] = node.prediction\n",
    "                break\n",
    "\n",
    "            feature_id = node.cutoff_id\n",
    "            c = node.cutoff_val\n",
    "\n",
    "            if data_point[feature_id] <= c:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "\n",
    "            if node is None:  # If no more children, use parent's prediction\n",
    "                pred[i] = node.prediction\n",
    "\n",
    "    return pred    \n",
    "\n",
    "def evaltree(root,xTe):\n",
    "    \"\"\"Evaluates xTe using decision tree root.\n",
    "    \n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "    \n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    # TODO:\n",
    "    return evaltreehelper(root, xTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ad988",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cursor = sql_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [\"Games\", \"MPG\", \"FGP\", \"3PP\", \"3P\", \"3PA\", \"FG\", \"FGA\", \"FT\", \"FTA\", \"FTP\", \"RPG\", \"APG\", \"SPG\", \"BPG\", \"\"]\n",
    "xTr = load_data(cursor, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
